### 游늭 `readmes/03-validacao.md`

Este passo implementa o **m칩dulo de valida칞칚o de dados**, respons치vel por garantir que os dados extra칤dos atendem a crit칠rios m칤nimos de qualidade antes de continuar no pipeline.

---

## 游댰 Objetivo
- Detectar **duplicatas, valores nulos e tipos inv치lidos**.
- Checar **regras de neg칩cio** importantes (ex.: total_value > 0, orders com customer_id v치lido).
- Retornar um relat칩rio estruturado com status PASS/FAIL.

---

## 游댰 Estrutura utilizada
- `data/orders.csv`
- `data/customers.csv`
- `src/validation/data_quality.py`

---

## 游댰 Exemplo de Execu칞칚o
```bash
cd src
python validation/data_quality.py
```

## 游댰 Sa칤da esperada
```bash
游늵 Relat칩rio Orders:
{   'dataset': 'orders',
    'errors': {   'duplicate_order_id': 101,
                  'invalid_amount': 124,
                  'missing_total_value': 78},
    'status': 'FAILED',
    'total_records': 5000,
    'validated_at': '2025-08-29T23:28:39.670903'}

游늵 Relat칩rio Customers:
{   'dataset': 'customers',
    'errors': {},
    'status': 'PASSED',
    'total_records': 1000,
    'validated_at': '2025-08-29T23:28:39.671907'}
```
## 游댰 Resultado
- O dataset de Orders foi marcado como FAILED devido a:
    - 101 IDs duplicados (duplicate_order_id)
    - 78 valores nulos em total_value (missing_total_value)
    - 124 valores inv치lidos (total_value <= 0) (invalid_amount)
- O dataset de Customers foi marcado como PASSED, sem erros.
- Pr칩xima etapa: tratar inconsist칡ncias detectadas e preparar envio ao Data Lake (S3).

<hr style="height:2px; background-color:#807f7e; border:none;"/>